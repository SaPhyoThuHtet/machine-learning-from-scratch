An algorithm trains a model that produces the predictions.
Each step can be evaluated in terms of transparency or interpretability.
Step တစ်ခုချင်းစီကို transparency နှင့်ဖြစ်​စေ interpretability နှင့် ဖြစ်​စေ တိုင်းတာလို့ ရပါတယ်။

**3.3.1 Algorithm Transparency**

How does the algorithm create the model?
Algorithm က model ကို ဘယ်လို ဖန်တီးတာလဲ?

Algorithm transparency is about how the algorithm learns a model from the data and what kind of relationships it can learn.
ဒီစာအုပ်မှာ​တော့ Algorithm Transparency အ​ကြောင်း အများကြီး ​ပြောသွားမှာ မဟုတ်ပါဘူး။

Algorithms such as the least squares method for linear models are well studied and understood. း
They are characterized by a high transparency.
Deep learning approaches (pushing a gradient through a network with millions of weights) are less well understood and the inner workings are the focus of ongoing research.
They are considered less transparent.
Least Square Methods ​တွေက ​သေချာ​လေ့လာထားပြီး နားလည်းထားပြီးဖြစ်တာ​ကြောင့် transparent ဖြစ်တယ်လို့ ​ပြောလို့ရတယ်။
Deep learning ​တွေက​တော့ less transparent ဖြစ်​နေတုန်း​ပေါ့။

**3.3.2 Global, Holistic Model Interpretability**

How does the trained model make predictions?
Trained Model က prediction ​တွေ ဘယ်လိုလုပ်တာလဲ?

To explain the global model output, you need the trained model, knowledge of the algorithm and the data. 
Global Model Output ကိုရှင်းပြဖို့ဆိုရင် trained model လိုမယ်။ knowledge of algo နဲ့ data လိုမယ်။

This level of interpretability is about understanding how the model makes decisions, based on a holistic view of its features and each of the learned components such as weights, other parameters, and structures. 
ခုinterpretability level ဟာဆိုရင် feature တို့ weights တို့ parameter တို့ကို အ​ခြေခံပြီး model က decision ဘယ်လို လုပ်သွားလဲဆိုတာကို နားလည်တဲ့ အဆင့်ပဲ ဖြစ်ပါသည်။

Which features are important and what kind of interactions between them take place? 
Global model interpretability helps to understand the distribution of your target outcome based on the features. 
ဘယ် feature ​တွေက အ​​ရေးကြီးလဲ နဲ့ interactions ​တွေကဆိုတာ​တွေ​ပေါ့။

Global model interpretability is very difficult to achieve in practice. Any model that exceeds a handful of parameters or weights is unlikely to fit into the short-term memory of the average human. I argue that you cannot really imagine a linear model with 5 features, because it would mean drawing the estimated hyperplane mentally in a 5-dimensional space. Any feature space with more than 3 dimensions is simply inconceivable for humans. Usually, when people try to comprehend a model, they consider only parts of it, such as the weights in linear models.
Global model interpretability က လက်​တွေ့မှာ ရဖို့ခက်တယ်။ လူ​တွေက 3 dimension အထက်ဆို နားလည်ဖို့က ခက်တယ်မှတ်လား အဲ့တာဆို​တော့ parameter ​တွေ feature ​တွေများလာရင် အဆင်ဘယ်​ပြေမလဲ။

**3.3.3 Global Model Interpretability on a Modular Level**

How do parts of the model affect predictions?








