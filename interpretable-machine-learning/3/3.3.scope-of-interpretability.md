An algorithm trains a model that produces the predictions.
Each step can be evaluated in terms of transparency or interpretability.
Step တစ်ခုချင်းစီကို transparency နှင့်ဖြစ်​စေ interpretability နှင့် ဖြစ်​စေ တိုင်းတာလို့ ရပါတယ်။

**3.3.1 Algorithm Transparency**

How does the algorithm create the model?
Algorithm က model ကို ဘယ်လို ဖန်တီးတာလဲ?

Algorithm transparency is about how the algorithm learns a model from the data and what kind of relationships it can learn.
ဒီစာအုပ်မှာ​တော့ Algorithm Transparency အ​ကြောင်း အများကြီး ​ပြောသွားမှာ မဟုတ်ပါဘူး။

Algorithms such as the least squares method for linear models are well studied and understood. း
They are characterized by a high transparency.
Deep learning approaches (pushing a gradient through a network with millions of weights) are less well understood and the inner workings are the focus of ongoing research.
They are considered less transparent.
Least Square Methods ​တွေက ​သေချာ​လေ့လာထားပြီး နားလည်းထားပြီးဖြစ်တာ​ကြောင့် transparent ဖြစ်တယ်လို့ ​ပြောလို့ရတယ်။
Deep learning ​တွေက​တော့ less transparent ဖြစ်​နေတုန်း​ပေါ့။

**3.3.2 Global, Holistic Model Interpretability**

How does the trained model make predictions?
Trained Model က prediction ​တွေ ဘယ်လိုလုပ်တာလဲ?

To explain the global model output, you need the trained model, knowledge of the algorithm and the data. 
Global Model Output ကိုရှင်းပြဖို့ဆိုရင် trained model လိုမယ်။ knowledge of algo နဲ့ data လိုမယ်။

This level of interpretability is about understanding how the model makes decisions, based on a holistic view of its features and each of the learned components such as weights, other parameters, and structures. 
ခုinterpretability level ဟာဆိုရင် feature တို့ weights တို့ parameter တို့ကို အ​ခြေခံပြီး model က decision ဘယ်လို လုပ်သွားလဲဆိုတာကို နားလည်တဲ့ အဆင့်ပဲ ဖြစ်ပါသည်။

Which features are important and what kind of interactions between them take place? 
Global model interpretability helps to understand the distribution of your target outcome based on the features. 
ဘယ် feature ​တွေက အ​​ရေးကြီးလဲ နဲ့ interactions ​တွေကဆိုတာ​တွေ​ပေါ့။

Global model interpretability is very difficult to achieve in practice. Any model that exceeds a handful of parameters or weights is unlikely to fit into the short-term memory of the average human. I argue that you cannot really imagine a linear model with 5 features, because it would mean drawing the estimated hyperplane mentally in a 5-dimensional space. Any feature space with more than 3 dimensions is simply inconceivable for humans. Usually, when people try to comprehend a model, they consider only parts of it, such as the weights in linear models.
Global model interpretability က လက်​တွေ့မှာ ရဖို့ခက်တယ်။ လူ​တွေက 3 dimension အထက်ဆို နားလည်ဖို့က ခက်တယ်မှတ်လား အဲ့တာဆို​တော့ parameter ​တွေ feature ​တွေများလာရင် အဆင်ဘယ်​ပြေမလဲ။

**3.3.3 Global Model Interpretability on a Modular Level**

How do parts of the model affect predictions?
While global model interpretability is usually out of reach, 
there is a good chance of understanding at least some models on a modular level. 

Not all models are interpretable at a parameter level.
For linear models, the interpretable parts are the weights, for trees it would be the splits (selected features plus cut-off points) and leaf node predictions.
Linear models ​တွေအတွက် interpretable ဖြစ်တဲ့ အပိုင်း​တွေက weights ​တွေ ဖြစ်ပြီး။ ....

Linear models, for example, look like as if they could be perfectly interpreted on a modular level, but the interpretation of a single weight is interlocked with all other weights. 

linear model that predicts the value of a house, that takes into account both the size of the house and the number of rooms, can have a negative weight for the room feature.  It can happen because there is already the highly correlated house size feature. In a market where people prefer larger rooms, a house with fewer rooms could be worth more than a house with more rooms if both have the same size. **The weights only make sense in the context of the other features in the model.**  Linear Model က Number of rooms ဆိုတဲ့ Feature မှာ Negative Weight ရှိကောင်းရှိနိုင်တယ်။ ဒါပေမယ့် လက်တွေ့ Real World မှာကျpeople prefer larger rooms, a house with fewer rooms could be worth more than a house with more rooms if both have the same size တာမျိုးရှိနိုင်တယ်။ 


But the weights in a linear model can still be interpreted better than the weights of a deep neural network.










